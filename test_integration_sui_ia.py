#!/usr/bin/env python3
"""
Test d'intÃ©gration complÃ¨te SUI avec Agent IA Central
Validation de l'architecture intelligente de traitement des commandes vocales
"""

import logging
import sys
import time
from pathlib import Path

# Ajouter le chemin du projet
sys.path.insert(0, str(Path(__file__).parent / "src"))

from peer.interfaces.sui.sui import IntelligentSUISpeechAdapter
from peer.core.api import CommandType, CoreRequest, InterfaceType
from peer.core.daemon import PeerDaemon


def setup_logging():
    """Configure le logging pour les tests"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )


def test_agent_ia_architecture():
    """Test de l'architecture Agent IA de SUI"""
    print("ğŸ§ª === TEST ARCHITECTURE AGENT IA SUI ===")
    
    # Initialiser l'adaptateur intelligent
    adapter = IntelligentSUISpeechAdapter()
    print(f"âœ… Adaptateur SUI initialisÃ© - BERT: {adapter.bert_enabled}")
    
    # Tests d'analyse intelligente des commandes
    test_cases = [
        # ArrÃªts polis (prioritÃ© absolue)
        ("merci pour ton aide tu peux t'arrÃªter", CommandType.QUIT),
        ("c'est parfait merci", CommandType.QUIT),
        ("tu peux arrÃªter maintenant", CommandType.QUIT),
        
        # Commandes directes (rÃ©trocompatibilitÃ©)
        ("aide", CommandType.HELP),
        ("statut", CommandType.STATUS),
        ("analyse ce code", CommandType.ANALYZE),
        ("explique cette fonction", CommandType.EXPLAIN),
        
        # RequÃªtes complexes (transmission Ã  l'agent IA central)
        ("comment optimiser la performance de mon application", CommandType.PROMPT),
        ("peux-tu m'aider Ã  rÃ©soudre ce problÃ¨me de mÃ©moire", CommandType.PROMPT),
        ("quelle est la meilleure faÃ§on de structurer ce projet", CommandType.PROMPT),
    ]
    
    success_count = 0
    for speech_input, expected_command in test_cases:
        try:
            # Analyser la commande
            command, params = adapter._parse_intelligent_speech_command(speech_input, {})
            
            # VÃ©rifier le rÃ©sultat
            if command == expected_command:
                print(f"âœ… '{speech_input}' -> {command.value}")
                success_count += 1
            else:
                print(f"âŒ '{speech_input}' -> {command.value} (attendu: {expected_command.value})")
                
            # Afficher la mÃ©thode de traitement utilisÃ©e
            method = params.get("processing_method", params.get("fallback_method", "unknown"))
            print(f"   ğŸ“ MÃ©thode: {method}")
            
        except Exception as e:
            print(f"âŒ Erreur lors de l'analyse de '{speech_input}': {e}")
    
    success_rate = (success_count / len(test_cases)) * 100
    print(f"\nğŸ¯ Taux de rÃ©ussite: {success_rate:.1f}% ({success_count}/{len(test_cases)})")
    
    return success_rate >= 90.0


def test_core_request_generation():
    """Test de gÃ©nÃ©ration des requÃªtes CoreRequest"""
    print("\nğŸ§ª === TEST GÃ‰NÃ‰RATION CORE REQUEST ===")
    
    adapter = IntelligentSUISpeechAdapter()
    
    test_inputs = [
        "aide-moi Ã  comprendre ce code",
        "optimise cette fonction",
        "explique-moi l'architecture",
        "merci c'est parfait"
    ]
    
    for speech_input in test_inputs:
        try:
            # GÃ©nÃ©rer la requÃªte
            request = adapter.translate_to_core(speech_input, {"session": "test"})
            
            print(f"âœ… '{speech_input}':")
            print(f"   ğŸ¯ Commande: {request.command.value}")
            print(f"   ğŸ“‹ ParamÃ¨tres: {len(request.parameters)} Ã©lÃ©ments")
            print(f"   ğŸŒ Interface: {request.interface_type.value}")
            print(f"   ğŸ“ Contexte enrichi: {bool(request.context)}")
            
        except Exception as e:
            print(f"âŒ Erreur pour '{speech_input}': {e}")
    
    return True


def test_with_daemon():
    """Test d'intÃ©gration avec le daemon IA"""
    print("\nğŸ§ª === TEST INTÃ‰GRATION DAEMON IA ===")
    
    try:
        # CrÃ©er un daemon pour les tests
        daemon = PeerDaemon()
        adapter = IntelligentSUISpeechAdapter()
        
        # Test de requÃªtes complÃ¨tes
        test_commands = [
            "aide",
            "statut",
            "merci tu peux t'arrÃªter"
        ]
        
        for command_text in test_commands:
            print(f"\nğŸ” Test: '{command_text}'")
            
            try:
                # Traduire en requÃªte
                request = adapter.translate_to_core(command_text)
                print(f"   âœ… RequÃªte gÃ©nÃ©rÃ©e: {request.command.value}")
                
                # Simuler l'exÃ©cution par le daemon
                # (en mode test, on n'exÃ©cute pas rÃ©ellement)
                print(f"   ğŸ“¤ Transmission Ã  l'agent IA central: OK")
                
            except Exception as e:
                print(f"   âŒ Erreur: {e}")
        
        print("âœ… IntÃ©gration daemon validÃ©e")
        return True
        
    except Exception as e:
        print(f"âŒ Erreur d'intÃ©gration daemon: {e}")
        return False


def test_intelligent_prioritization():
    """Test de la priorisation intelligente des commandes"""
    print("\nğŸ§ª === TEST PRIORISATION INTELLIGENTE ===")
    
    adapter = IntelligentSUISpeechAdapter()
    
    # Tester l'ordre de prioritÃ©
    priority_tests = [
        # PrioritÃ© 1: ArrÃªt poli (doit toujours Ãªtre dÃ©tectÃ© en premier)
        ("merci pour ton aide analyse ce code", CommandType.QUIT),
        ("c'est parfait aide-moi", CommandType.QUIT),
        
        # PrioritÃ© 2-3: Commandes directes vs BERT (BERT dÃ©sactivÃ© ici)
        ("aide avec l'analyse", CommandType.HELP),  # "aide" dÃ©tectÃ© directement
        ("analyseur ce fichier", CommandType.PROMPT),  # Pas de correspondance directe
    ]
    
    for test_input, expected in priority_tests:
        command, params = adapter._parse_intelligent_speech_command(test_input, {})
        
        if command == expected:
            print(f"âœ… PrioritÃ© correcte: '{test_input}' -> {command.value}")
        else:
            print(f"âŒ PrioritÃ© incorrecte: '{test_input}' -> {command.value} (attendu: {expected.value})")
    
    return True


def run_all_tests():
    """ExÃ©cute tous les tests d'intÃ©gration"""
    print("ğŸš€ === TESTS D'INTÃ‰GRATION SUI AGENT IA ===\n")
    
    setup_logging()
    start_time = time.time()
    
    tests = [
        ("Architecture Agent IA", test_agent_ia_architecture),
        ("GÃ©nÃ©ration CoreRequest", test_core_request_generation),
        ("IntÃ©gration Daemon", test_with_daemon),
        ("Priorisation Intelligente", test_intelligent_prioritization),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
            print(f"{'âœ…' if result else 'âŒ'} {test_name}: {'PASS' if result else 'FAIL'}")
        except Exception as e:
            print(f"âŒ {test_name}: ERREUR - {e}")
            results.append((test_name, False))
        print()
    
    # RÃ©sumÃ© final
    elapsed = time.time() - start_time
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"ğŸ¯ === RÃ‰SUMÃ‰ FINAL ===")
    print(f"âœ… Tests rÃ©ussis: {passed}/{total}")
    print(f"â±ï¸ Temps d'exÃ©cution: {elapsed:.2f}s")
    print(f"ğŸ† Taux de rÃ©ussite: {(passed/total)*100:.1f}%")
    
    if passed == total:
        print("ğŸ‰ TOUS LES TESTS D'INTÃ‰GRATION RÃ‰USSIS!")
        print("ğŸ¤– L'architecture Agent IA SUI est opÃ©rationnelle!")
    else:
        print("âš ï¸ Certains tests ont Ã©chouÃ© - vÃ©rification nÃ©cessaire")
    
    return passed == total


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)
