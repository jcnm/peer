#!/usr/bin/env python3
"""
Interface SUI avec communication orale en temps r√©el ultra-rapide.

Cette interface permet :
- Communication orale bidirectionnelle en fran√ßais
- Transcription en temps r√©el imm√©diate sans batching
- Affichage continu de ce qui est √©cout√© 
- Exp√©rience utilisateur fluide et r√©active
"""

import os
import sys
import time
import threading
import logging
from typing import Optional, Dict, Any
from pathlib import Path
import queue
import numpy as np

# Configuration pour √©viter les warnings OMP
os.environ["OMP_NUM_THREADS"] = "1"

# Configuration des logs
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(os.path.expanduser('~/.peer/sui_realtime.log'), mode='a')
    ]
)

# Ajouter le chemin source pour l'importation
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, os.path.join(current_dir, 'src'))
sys.path.insert(0, current_dir)

from peer.interfaces.sui.stt.speech_recognizer import SpeechRecognizer
from peer.interfaces.sui.stt.audio_io import AudioCapture, VoiceActivityDetector, VADMode, AudioFormat
from peer.interfaces.sui.tts.simple_tts_engine import SimpleTTS
from peer.interfaces.sui.domain.models import SpeechRecognitionResult


class RealtimeVoiceInterface:
    """Interface de communication orale en temps r√©el ultra-rapide."""
    
    def __init__(self):
        self.logger = logging.getLogger("RealtimeVoiceInterface")
        
        # √âtat de l'interface
        self.running = False
        self.listening = False
        self.speaking = False
        self._last_speech_time = 0  # Pour suivre quand l'IA a fini de parler
        self._last_spoken_text = ""  # Pour d√©tecter les √©chos
        
        # Composants
        self.speech_recognizer: Optional[SpeechRecognizer] = None
        self.audio_capture: Optional[AudioCapture] = None
        self.vad: Optional[VoiceActivityDetector] = None
        self.tts_engine: Optional[SimpleTTS] = None
        
        # Buffer audio pour transcription directe
        self.audio_buffer = np.array([], dtype=np.float32)
        self.audio_buffer_lock = threading.Lock()
        self.transcription_thread = None
        self.last_transcription_time = 0
        
        # Affichage
        self.current_transcription = ""
        self.final_transcription = ""
        self.display_lock = threading.Lock()
        
        # M√©triques
        self.session_stats = {
            'start_time': time.time(),
            'total_speech_time': 0.0,
            'transcriptions_count': 0,
            'words_transcribed': 0
        }
        
        self._init_components()
    
    def _init_components(self):
        """Initialise tous les composants n√©cessaires."""
        self.logger.info("üöÄ Initialisation de l'interface vocale en temps r√©el ultrarapide")
        
        try:
            # Configuration WhisperX avec mod√®le small pour bon compromis
            stt_config = {
                'stt_settings': {
                    'engines': {
                        'whisperx': {
                            'enabled': True,
                            'model_name': 'small',  # Mod√®le √©quilibr√© (244 MB)
                            'language': 'fr',
                            'priority': 1,
                            'parameters': {
                                'batch_size': 3,    # Batch mod√©r√©
                                'task': 'transcribe',
                                'language': 'french'
                            }
                        }
                    }
                }
            }
            
            # Initialiser le recognizer
            self.speech_recognizer = SpeechRecognizer(stt_config)
            self.logger.info("‚úÖ Speech recognizer initialis√©")
            
            # Initialiser la capture audio
            audio_config = {
                'sample_rate': AudioFormat.SAMPLE_RATE,
                'channels': AudioFormat.CHANNELS,
                'chunk_size': AudioFormat.CHUNK_SIZE,
                'vad_sensitivity': 3  # Mode VERY_AGGRESSIVE pour maximiser la d√©tection
            }
            self.audio_capture = AudioCapture(audio_config)
            self.logger.info("‚úÖ Capture audio initialis√©e")
            
            # Initialiser le VAD (Voice Activity Detection)
            self.vad = VoiceActivityDetector(mode=VADMode.VERY_AGGRESSIVE)
            self.logger.info("‚úÖ VAD initialis√©")
            
            # Initialiser le TTS pour les r√©ponses
            from peer.interfaces.sui.tts.base import TTSConfig, TTSEngineType
            tts_config = TTSConfig(
                engine_type=TTSEngineType.SIMPLE,
                language='fr',
                voice='Audrey (Premium)'
            )
            self.tts_engine = SimpleTTS(tts_config)
            self.logger.info("‚úÖ Moteur TTS initialis√©")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'initialisation: {e}")
            raise
    
    def start(self):
        """D√©marre l'interface de communication orale."""
        if self.running:
            self.logger.warning("Interface d√©j√† en cours")
            return
        
        self.running = True
        self.logger.info("üéôÔ∏è D√©marrage de l'interface vocale ultrarapide")
        
        # Message de bienvenue
        welcome_message = (
            "Interface vocale en temps r√©el d√©marr√©e. "
            "Vous pouvez parler et voir la transcription imm√©diatement. "
            "Dites 'arr√™ter' pour terminer."
        )
        self._speak_async(welcome_message)
        
        # Afficher l'interface
        self._display_interface()
        
        # D√©marrer l'√©coute audio et la transcription continue
        self._start_realtime_listening()
        
        # Boucle principale
        self._main_loop()
    
    def stop(self):
        """Arr√™te l'interface de communication orale."""
        self.running = False
        self.listening = False
        
        if self.audio_capture:
            self.audio_capture.stop_recording()
        
        self.logger.info("üõë Interface vocale arr√™t√©e")
        
        # Afficher les statistiques finales
        self._display_final_stats()
    
    def _start_realtime_listening(self):
        """D√©marre l'√©coute audio avec transcription en temps r√©el."""
        self.listening = True
        
        # D√©marrer l'enregistrement
        if not self.audio_capture.start_recording():
            self.logger.error("‚ùå Impossible de d√©marrer l'enregistrement audio")
            return
            
        # Thread pour traiter l'audio et transcription continue
        def audio_processing_thread():
            buffer_update_count = 0
            transcription_count = 0
            
            while self.running and self.listening:
                if self.speaking:
                    # Pause pendant que l'IA parle
                    time.sleep(0.1)
                    
                    # Vider la file d'attente audio pour √©viter les √©chos
                    try:
                        while not self.audio_capture.audio_queue.empty():
                            self.audio_capture.audio_queue.get_nowait()
                    except:
                        pass
                    
                    # R√©initialiser le buffer audio apr√®s la parole
                    with self.audio_buffer_lock:
                        self.audio_buffer = np.array([], dtype=np.float32)
                        
                    continue
                
                # R√©cup√©rer le prochain segment audio
                segment = self.audio_capture.get_audio_segment(timeout=0.1)
                if segment is None:
                    continue
                
                # V√©rifier si c'est un √©cho
                recently_spoke = hasattr(self, '_last_speech_time') and \
                               (time.time() - self._last_speech_time < 1.0)
                
                if recently_spoke and segment.energy_level < 0.01:
                    # Ignorer les segments probablement caus√©s par un √©cho
                    continue
                
                # Ajouter l'audio au buffer si suffisamment d'√©nergie
                if segment.has_speech and segment.energy_level >= 0.005:
                    with self.audio_buffer_lock:
                        # Ajouter le nouveau segment au buffer
                        if len(self.audio_buffer) == 0:
                            self.audio_buffer = segment.data.copy()
                        else:
                            # Concat√©ner mais limiter la taille du buffer √† ~3 secondes max
                            # pour garder la transcription rapide
                            self.audio_buffer = np.concatenate([self.audio_buffer, segment.data])
                            if len(self.audio_buffer) > 48000:  # 3 secondes √† 16kHz
                                # Garder les 3 derni√®res secondes
                                self.audio_buffer = self.audio_buffer[-48000:]
                        
                        buffer_update_count += 1
                        
                        # Effectuer une transcription apr√®s chaque ajout si suffisamment de temps √©coul√©
                        # (pour √©viter de surcharger le CPU)
                        current_time = time.time()
                        time_since_last = current_time - self.last_transcription_time
                        
                        # Transcrire plus fr√©quemment (toutes les 200ms)
                        if time_since_last >= 0.2 and len(self.audio_buffer) > 1600:  # au moins 100ms d'audio
                            # Copier le buffer pour √©viter les modifications pendant la transcription
                            audio_to_transcribe = self.audio_buffer.copy()
                            
                            # Transcription rapide
                            threading.Thread(
                                target=self._transcribe_audio, 
                                args=(audio_to_transcribe, False),
                                daemon=True
                            ).start()
                            
                            self.last_transcription_time = current_time
                            transcription_count += 1
                
                # Pause d√©tect√©e ou silence prolong√©? Finaliser la transcription
                elif not segment.has_speech and len(self.audio_buffer) > 0:
                    pause_duration = 0.5  # Finaliser apr√®s 500ms de silence
                    if time.time() - self.last_transcription_time >= pause_duration:
                        with self.audio_buffer_lock:
                            if len(self.audio_buffer) > 0:
                                # Transcription finale
                                audio_to_transcribe = self.audio_buffer.copy()
                                threading.Thread(
                                    target=self._transcribe_audio, 
                                    args=(audio_to_transcribe, True),
                                    daemon=True
                                ).start()
                                
                                # R√©initialiser le buffer apr√®s finalisation
                                self.audio_buffer = np.array([], dtype=np.float32)
                
                # Log p√©riodique
                if buffer_update_count % 100 == 0:
                    self.logger.info(f"üìä Mises √† jour buffer: {buffer_update_count}, Transcriptions: {transcription_count}")
        
        # D√©marrer le thread de traitement audio
        self.transcription_thread = threading.Thread(target=audio_processing_thread, daemon=True)
        self.transcription_thread.start()
        
        self.logger.info("üëÇ √âcoute et transcription en temps r√©el d√©marr√©es")
    
    def _transcribe_audio(self, audio_data: np.ndarray, is_final: bool):
        """Transcrit l'audio en texte."""
        try:
            start_time = time.time()
            
            # Transcription avec param√®tres optimis√©s pour la vitesse
            result = self.speech_recognizer.transcribe_audio(
                audio_data,
                use_alignment=(is_final)  # Utiliser l'alignement seulement pour les transcriptions finales
            )
            
            processing_time = time.time() - start_time
            
            if result and result.text.strip():
                text = result.text.strip()
                
                # √âviter les √©chos
                if hasattr(self, '_last_spoken_text') and self._last_spoken_text:
                    similarity = self._text_similarity(text.lower(), self._last_spoken_text.lower())
                    if similarity > 0.5:  # Plus de 50% de similarit√© = probablement un √©cho
                        self.logger.info(f"üîá √âcho probable ignor√© (similarit√© {similarity:.2f}): '{text}'")
                        return
                
                # Mettre √† jour l'affichage
                with self.display_lock:
                    if is_final:
                        self.final_transcription = text
                        self.current_transcription = ""
                        
                        # Traiter la commande finale
                        self._process_voice_command(text)
                        
                        # Mettre √† jour les stats
                        self.session_stats['transcriptions_count'] += 1
                        self.session_stats['words_transcribed'] += len(text.split())
                        
                        self.logger.info(f"‚úÖ Transcription finale ({processing_time:.2f}s): '{text}'")
                    else:
                        self.current_transcription = text
                        self.logger.debug(f"üî§ Transcription partielle ({processing_time:.2f}s): '{text}'")
                
                # Mettre √† jour l'affichage
                self._update_display()
                
        except Exception as e:
            self.logger.error(f"‚ùå Erreur transcription: {e}")
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """
        Calcule la similarit√© entre deux textes.
        Retourne une valeur entre 0 (compl√®tement diff√©rents) et 1 (identiques).
        """
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0.0
            
        common_words = words1.intersection(words2)
        total_unique_words = len(words1.union(words2))
        
        return len(common_words) / total_unique_words if total_unique_words > 0 else 0.0
    
    def _process_voice_command(self, text: str):
        """Traite une commande vocale re√ßue en r√©p√©tant simplement le texte."""
        self.logger.info(f"üó£Ô∏è Transcription finale: '{text}'")
        
        # Construire la r√©ponse
        response = f"Vous avez dit : {text}"
        
        # M√©moriser le texte parl√© pour la d√©tection d'√©cho
        self._last_spoken_text = response
        
        # Parler la r√©ponse
        self._speak_async(response)
        
        # L'interface retourne automatiquement √† l'√©coute apr√®s que _speak_async ait termin√©
        # et que self.speaking soit remis √† False.
    
    def _speak_async(self, text: str):
        """Synth√®se vocale asynchrone."""
        def speak_worker():
            # Marquer comme parlant pour emp√™cher l'√©coute
            self.speaking = True
            self.logger.info(f"üîä TTS: '{text}'")
            
            try:
                # Vider le buffer audio avant de parler pour √©viter les √©chos
                with self.audio_buffer_lock:
                    self.audio_buffer = np.array([], dtype=np.float32)
                
                # Effectuer la synth√®se vocale
                start_time = time.time()
                result = self.tts_engine.synthesize(text)
                
                if result.success:
                    # Calculer la dur√©e approximative de la parole
                    speech_duration = len(text) / 15.0
                    actual_duration = time.time() - start_time
                    
                    # Attendre un peu apr√®s la fin de la parole pour √©viter les √©chos
                    cooldown = max(0.5, speech_duration * 0.2)
                    time.sleep(cooldown)
                    
                    # Marquer le temps de fin de parole pour la d√©tection d'√©cho
                    self._last_speech_time = time.time()
                else:
                    self.logger.error(f"‚ùå Erreur TTS: {result.message}")
            except Exception as e:
                self.logger.error(f"‚ùå Erreur TTS: {e}")
            finally:
                # R√©initialiser l'√©tat de parole
                self.speaking = False
                self.logger.debug("üéôÔ∏è Reprise de l'√©coute")
        
        threading.Thread(target=speak_worker, daemon=True).start()
    
    def _display_interface(self):
        """Affiche l'interface utilisateur."""
        print("\n" + "="*80)
        print("üéôÔ∏è INTERFACE VOCALE ULTRA-RAPIDE - TRANSCRIPTION INSTANTAN√âE")
        print("="*80)
        print("üìã Commandes disponibles:")
        print("   ‚Ä¢ Parlez naturellement, votre voix est transcrite imm√©diatement")
        print("   ‚Ä¢ 'aide' - Afficher l'aide")
        print("   ‚Ä¢ 'heure' - Demander l'heure")
        print("   ‚Ä¢ 'arr√™ter' - Terminer l'interface")
        print("\nüî¥ √âTAT: En √©coute... Parlez maintenant.\n")
    
    def _update_display(self):
        """Met √† jour l'affichage de la transcription."""
        with self.display_lock:
            # Effacer les lignes pr√©c√©dentes
            print("\r" + " " * 100, end="\r")
            
            # Afficher la transcription
            if self.current_transcription:
                print(f"üé§ [En direct]: {self.current_transcription}", end="\r")
            elif self.final_transcription:
                print(f"‚úÖ [Final]: {self.final_transcription}")
                print("üî¥ En √©coute...", end="\r")
    
    def _main_loop(self):
        """Boucle principale de l'interface."""
        try:
            while self.running:
                time.sleep(0.1)
                
                # Mise √† jour p√©riodique de l'affichage
                if time.time() % 5 < 0.1:  # Toutes les 5 secondes
                    self._show_status()
                
        except KeyboardInterrupt:
            print("\n‚å®Ô∏è Interruption clavier d√©tect√©e")
            self.stop()
    
    def _show_status(self):
        """Affiche le statut p√©riodique."""
        session_duration = time.time() - self.session_stats['start_time']
        
        status = (
            f"‚è±Ô∏è Session: {session_duration:.0f}s | "
            f"üìù Transcriptions: {self.session_stats['transcriptions_count']} | "
            f"üìà Mots: {self.session_stats['words_transcribed']}"
        )
        
        # Afficher en bas de l'√©cran sans perturber la transcription
        print(f"\n{status}", end="\r")
    
    def _display_final_stats(self):
        """Affiche les statistiques finales."""
        session_duration = time.time() - self.session_stats['start_time']
        
        print("\n\n" + "="*80)
        print("üìä STATISTIQUES DE LA SESSION")
        print("="*80)
        print(f"‚è±Ô∏è Dur√©e totale: {session_duration:.1f} secondes")
        print(f"üìù Transcriptions finales: {self.session_stats['transcriptions_count']}")
        print(f"üìà Mots transcrits: {self.session_stats['words_transcribed']}")
        
        if self.session_stats['transcriptions_count'] > 0:
            wpm = (self.session_stats['words_transcribed'] * 60) / session_duration
            print(f"üéØ Vitesse moyenne: {wpm:.1f} mots/minute")
        
        print("\n‚úÖ Session termin√©e. Merci d'avoir utilis√© l'interface!")


def main():
    """Point d'entr√©e principal."""
    try:
        print("üöÄ D√©marrage de l'interface vocale ultra-rapide...")
        
        # Cr√©er et d√©marrer l'interface
        interface = RealtimeVoiceInterface()
        interface.start()
        
    except KeyboardInterrupt:
        print("\n‚å®Ô∏è Arr√™t demand√© par l'utilisateur")
    except Exception as e:
        print(f"‚ùå Erreur fatale: {e}")
        logging.error(f"Erreur fatale dans l'interface: {e}")
    
    print("\nüëã Au revoir!")


if __name__ == "__main__":
    main()
