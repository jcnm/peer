"""
Module de reconnaissance vocale automatique (ASR).

Ce module gÃ¨re :
- Reconnaissance vocale avec diffÃ©rents moteurs (WhisperX, Vosk)
- SystÃ¨me de fallback automatique
- Gestion des modÃ¨les et configurations
- Optimisation des performances
"""

import logging
import time
import tempfile
import wave
import os
import json
import numpy as np
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from enum import Enum
from pathlib import Path

# Imports conditionnels pour les moteurs STT
try:
    import whisperx
    WHISPERX_AVAILABLE = True
except ImportError:
    WHISPERX_AVAILABLE = False
    whisperx = None

try:
    import vosk
    VOSK_AVAILABLE = True
except ImportError:
    VOSK_AVAILABLE = False
    vosk = None

from ..domain.models import SpeechRecognitionResult

class ASREngine(Enum):
    """Types de moteurs de reconnaissance vocale supportÃ©s."""
    WHISPERX = "whisperx"
    VOSK = "vosk"
    MOCK = "mock"

@dataclass
class ASRConfig:
    """Configuration pour un moteur ASR."""
    enabled: bool = True
    model_name: str = ""
    model_path: str = ""
    language: str = "fr"
    parameters: Dict[str, Any] = None
    priority: int = 10
    
    def __post_init__(self):
        if self.parameters is None:
            self.parameters = {}

class WhisperXASR:
    """Moteur de reconnaissance WhisperX (version amÃ©liorÃ©e)."""
    
    def __init__(self, config: ASRConfig):
        self.logger = logging.getLogger("WhisperXASR")
        self.config = config
        self.model = None
        self.align_model = None
        self.align_metadata = None
        
        if not WHISPERX_AVAILABLE:
            raise ImportError("WhisperX non disponible")
        
        self._load_model()
    
    def _load_model(self):
        """Charge le modÃ¨le WhisperX."""
        model_name = self.config.model_name or "base"
        
        try:
            self.logger.info(f"ðŸ“¥ Chargement WhisperX {model_name}...")
            
            # DÃ©terminer le device optimal
            device = "cpu"
            compute_type = "int8"
            
            # Essayer d'utiliser GPU si disponible
            try:
                import torch
                if torch.cuda.is_available():
                    device = "cuda"
                    compute_type = "float16"
                elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
                    # MPS sur macOS - utiliser CPU pour WhisperX pour Ã©viter les problÃ¨mes
                    device = "cpu"
                    compute_type = "int8"
            except ImportError:
                pass
            
            # Charger le modÃ¨le principal
            self.model = whisperx.load_model(
                model_name, 
                device=device,
                compute_type=compute_type
            )
            
            # Charger le modÃ¨le d'alignement pour la langue configurÃ©e
            try:
                language_code = self.config.language if self.config.language in ["en", "fr", "de", "es", "it", "ja", "zh", "nl", "uk", "pt"] else "en"
                self.align_model, self.align_metadata = whisperx.load_align_model(
                    language_code=language_code, 
                    device=device
                )
                self.logger.info(f"âœ… ModÃ¨le d'alignement chargÃ© pour {language_code}")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Impossible de charger le modÃ¨le d'alignement: {e}")
                self.align_model = None
                self.align_metadata = None
            
            self.logger.info(f"âœ… WhisperX {model_name} chargÃ© et configurÃ© sur {device}")
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur chargement WhisperX: {e}")
            raise
    
    def transcribe(self, audio_data: np.ndarray) -> Optional[SpeechRecognitionResult]:
        """
        Transcrit l'audio avec WhisperX.
        
        Args:
            audio_data: DonnÃ©es audio (numpy array, float32, 16kHz)
            
        Returns:
            RÃ©sultat de la transcription ou None
        """
        if self.model is None:
            return None
        
        try:
            start_time = time.time()
            
            # WhisperX transcription avec paramÃ¨tres optimisÃ©s
            result = self.model.transcribe(
                audio_data,
                batch_size=self.config.parameters.get("batch_size", 16),
                language=self.config.language if self.config.language != "auto" else None,
                task=self.config.parameters.get("task", "transcribe")
            )
            
            # VÃ©rifier s'il y a des segments
            if not result.get("segments"):
                return None
            
            # Appliquer l'alignement si disponible pour une meilleure prÃ©cision
            if self.align_model and self.align_metadata:
                try:
                    result = whisperx.align(
                        result["segments"], 
                        self.align_model, 
                        self.align_metadata, 
                        audio_data, 
                        device="cpu"  # Utiliser CPU pour l'alignement pour Ã©viter les problÃ¨mes
                    )
                except Exception as align_error:
                    self.logger.warning(f"âš ï¸ Ã‰chec alignement: {align_error}")
                    # Continuer sans alignement
            
            processing_time = time.time() - start_time
            
            # Extraire le texte des segments
            text_parts = []
            total_confidence = 0
            segment_count = 0
            
            for segment in result.get("segments", []):
                if "text" in segment and segment["text"].strip():
                    text_parts.append(segment["text"].strip())
                    
                    # Calculer la confiance
                    if "score" in segment:
                        total_confidence += segment["score"]
                        segment_count += 1
                    elif "confidence" in segment:
                        total_confidence += segment["confidence"]
                        segment_count += 1
            
            if not text_parts:
                return None
            
            text = " ".join(text_parts)
            confidence = total_confidence / segment_count if segment_count > 0 else 0.8
            
            # DÃ©tecter la langue si pas spÃ©cifiÃ©e
            detected_language = result.get("language", self.config.language)
            
            return SpeechRecognitionResult(
                text=text,
                confidence=confidence,
                language=detected_language,
                processing_time=processing_time,
                engine_used="whisperx"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur transcription WhisperX: {e}")
            return None

class VoskASR:
    """Moteur de reconnaissance Vosk."""
    
    def __init__(self, config: ASRConfig):
        self.logger = logging.getLogger("VoskASR")
        self.config = config
        self.model = None
        self.recognizer = None
        
        if not VOSK_AVAILABLE:
            raise ImportError("Vosk non disponible")
        
        self._load_model()
    
    def _load_model(self):
        """Charge le modÃ¨le Vosk."""
        model_path = self.config.model_path
        if not model_path or not os.path.exists(model_path):
            raise FileNotFoundError(f"ModÃ¨le Vosk non trouvÃ©: {model_path}")
        
        try:
            self.logger.info(f"ðŸ“¥ Chargement Vosk: {model_path}")
            self.model = vosk.Model(model_path)
            self.recognizer = vosk.KaldiRecognizer(self.model, 16000)  # 16kHz fixe pour Vosk
            
            self.logger.info(f"âœ… Vosk chargÃ©: {os.path.basename(model_path)}")
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur chargement Vosk: {e}")
            raise
    
    def transcribe(self, audio_data: np.ndarray) -> Optional[SpeechRecognitionResult]:
        """
        Transcrit l'audio avec Vosk.
        
        Args:
            audio_data: DonnÃ©es audio (numpy array, float32, 16kHz)
            
        Returns:
            RÃ©sultat de la transcription ou None
        """
        if self.recognizer is None:
            return None
        
        try:
            start_time = time.time()
            
            # Convertir en int16 pour Vosk
            audio_int16 = (audio_data * 32767).astype(np.int16)
            audio_bytes = audio_int16.tobytes()
            
            # Reset du recognizer
            self.recognizer.Reset()
            
            # Traitement par chunks
            chunk_size = 4000  # Chunk size pour Vosk
            final_result = None
            
            for i in range(0, len(audio_bytes), chunk_size):
                chunk = audio_bytes[i:i + chunk_size]
                if self.recognizer.AcceptWaveform(chunk):
                    result = json.loads(self.recognizer.Result())
                    if result.get("text"):
                        final_result = result
            
            # RÃ©cupÃ©rer le rÃ©sultat final
            if not final_result:
                final_result = json.loads(self.recognizer.FinalResult())
            
            processing_time = time.time() - start_time
            
            text = final_result.get("text", "").strip()
            if not text:
                return None
            
            # Vosk peut fournir une confiance
            confidence = final_result.get("confidence", 0.7)
            
            return SpeechRecognitionResult(
                text=text,
                confidence=confidence,
                language=self.config.language,
                processing_time=processing_time,
                engine_used="vosk"
            )
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur transcription Vosk: {e}")
            return None

class MockASR:
    """Moteur de reconnaissance simulÃ© pour les tests."""
    
    def __init__(self, config: ASRConfig):
        self.logger = logging.getLogger("MockASR")
        self.config = config
        self.responses = [
            "bonjour peer",
            "aide moi s'il te plaÃ®t",
            "quelle heure est-il",
            "quel est le statut du systÃ¨me", 
            "je voudrais des informations",
            "comment Ã§a marche",
            "merci beaucoup",
            "au revoir",
            "arrÃªte toi",
            "mode texte",
            "mode vocal"
        ]
        self.counter = 0
    
    def transcribe(self, audio_data: np.ndarray) -> SpeechRecognitionResult:
        """Retourne une transcription simulÃ©e."""
        response = self.responses[self.counter % len(self.responses)]
        self.counter += 1
        
        # Simuler un dÃ©lai de traitement
        time.sleep(0.1)
        
        return SpeechRecognitionResult(
            text=response,
            confidence=0.9,
            language=self.config.language,
            processing_time=0.1,
            engine_used="mock"
        )

class SpeechRecognizer:
    """
    Gestionnaire principal de reconnaissance vocale avec fallbacks.
    
    GÃ¨re plusieurs moteurs ASR avec basculement automatique en cas d'Ã©chec.
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.logger = logging.getLogger("SpeechRecognizer")
        self.config = config
        
        # Configuration des moteurs
        self.engine_configs = self._parse_engine_configs()
        self.engines = {}
        self.fallback_order = []
        
        self.logger.info("ðŸŽ¤ Initialisation du reconnaisseur vocal...")
        self._initialize_engines()
        self._setup_fallback_order()
        
        if not self.engines:
            raise RuntimeError("Aucun moteur ASR disponible")
        
        self.logger.info(f"âœ… Reconnaisseur vocal initialisÃ© avec {len(self.engines)} moteurs")
    
    def _parse_engine_configs(self) -> Dict[ASREngine, ASRConfig]:
        """Parse la configuration des moteurs."""
        configs = {}
        stt_config = self.config.get('stt_settings', {})
        engines_config = stt_config.get('engines', {})
        
        # Configuration par dÃ©faut
        default_configs = {
            ASREngine.WHISPERX: ASRConfig(
                enabled=True,
                model_name="base",
                language="fr",
                priority=1,
                parameters={"batch_size": 16, "task": "transcribe"}
            ),
            ASREngine.VOSK: ASRConfig(
                enabled=True,
                model_path="vepeer/models/vosk/vosk-model-fr-0.22",
                language="fr",
                priority=2
            ),
            ASREngine.MOCK: ASRConfig(
                enabled=True,
                language="fr",
                priority=99
            )
        }
        
        # Fusionner avec la configuration utilisateur
        for engine in ASREngine:
            engine_config = engines_config.get(engine.value, {})
            default_config = default_configs.get(engine, ASRConfig())
            
            # Mettre Ã  jour avec la config utilisateur
            config = ASRConfig(
                enabled=engine_config.get('enabled', default_config.enabled),
                model_name=engine_config.get('model_name', default_config.model_name),
                model_path=engine_config.get('model_path', default_config.model_path),
                language=engine_config.get('language', default_config.language),
                priority=engine_config.get('priority', default_config.priority),
                parameters={**default_config.parameters, **engine_config.get('parameters', {})}
            )
            
            configs[engine] = config
        
        return configs
    
    def _initialize_engines(self):
        """Initialise tous les moteurs ASR disponibles."""
        for engine_type, config in self.engine_configs.items():
            if not config.enabled:
                continue
            
            try:
                engine = self._create_engine(engine_type, config)
                if engine:
                    self.engines[engine_type] = engine
                    self.logger.info(f"âœ… Moteur {engine_type.value} initialisÃ©")
                
            except Exception as e:
                self.logger.warning(f"âš ï¸ Ã‰chec initialisation {engine_type.value}: {e}")
    
    def _create_engine(self, engine_type: ASREngine, config: ASRConfig):
        """CrÃ©e une instance de moteur ASR."""
        if engine_type == ASREngine.WHISPERX:
            return WhisperXASR(config)
        elif engine_type == ASREngine.VOSK:
            return VoskASR(config)
        elif engine_type == ASREngine.MOCK:
            return MockASR(config)
        else:
            raise ValueError(f"Moteur inconnu: {engine_type}")
    
    def _setup_fallback_order(self):
        """Configure l'ordre de fallback basÃ© sur les prioritÃ©s."""
        available_engines = list(self.engines.keys())
        
        # Trier par prioritÃ©
        self.fallback_order = sorted(
            available_engines,
            key=lambda e: self.engine_configs[e].priority
        )
        
        if self.fallback_order:
            primary = self.fallback_order[0]
            fallbacks = self.fallback_order[1:]
            
            self.logger.info(f"ðŸŽ¯ Moteur principal: {primary.value}")
            if fallbacks:
                fallback_names = [e.value for e in fallbacks]
                self.logger.info(f"ðŸ”„ Fallbacks: {', '.join(fallback_names)}")
    
    def transcribe(self, audio_data: np.ndarray) -> Optional[SpeechRecognitionResult]:
        """
        Transcrit l'audio en utilisant le systÃ¨me de fallback.
        
        Args:
            audio_data: DonnÃ©es audio (numpy array, float32, 16kHz)
            
        Returns:
            RÃ©sultat de transcription ou None si tous les moteurs Ã©chouent
        """
        if not audio_data.size or not self.fallback_order:
            return None
        
        last_error = None
        
        for engine_type in self.fallback_order:
            engine = self.engines.get(engine_type)
            if not engine:
                continue
            
            try:
                self.logger.debug(f"ðŸ”„ Tentative avec {engine_type.value}")
                result = engine.transcribe(audio_data)
                
                if result and result.text.strip():
                    self.logger.info(f"âœ… SuccÃ¨s avec {engine_type.value}: '{result.text}'")
                    return result
                
            except Exception as e:
                last_error = e
                self.logger.warning(f"âš ï¸ Ã‰chec {engine_type.value}: {e}")
                continue
        
        self.logger.error(f"âŒ Tous les moteurs ont Ã©chouÃ©. DerniÃ¨re erreur: {last_error}")
        return None
    
    def transcribe_audio(self, audio_data: np.ndarray, use_alignment: bool = False) -> Optional[SpeechRecognitionResult]:
        """
        Transcrit les donnÃ©es audio avec options avancÃ©es.
        
        Args:
            audio_data: DonnÃ©es audio (numpy array, float32, 16kHz)
            use_alignment: Utiliser l'alignement pour une meilleure prÃ©cision
            
        Returns:
            RÃ©sultat de la transcription ou None
        """
        # Utiliser la mÃ©thode standard pour la transcription
        result = self.transcribe(audio_data)
        
        # Si alignement demandÃ© et WhisperX disponible, amÃ©liorer la prÃ©cision
        if use_alignment and result and ASREngine.WHISPERX in self.engines:
            try:
                whisperx_engine = self.engines[ASREngine.WHISPERX]
                if hasattr(whisperx_engine, 'align_model') and whisperx_engine.align_model:
                    # Re-faire la transcription avec alignement forcÃ©
                    aligned_result = whisperx_engine.transcribe(audio_data)
                    if aligned_result and aligned_result.confidence > result.confidence:
                        result = aligned_result
                        self.logger.debug("ðŸŽ¯ Alignement appliquÃ© pour amÃ©liorer la prÃ©cision")
            except Exception as e:
                self.logger.warning(f"âš ï¸ Ã‰chec de l'alignement: {e}")
        
        return result
    
    def get_available_engines(self) -> List[str]:
        """Retourne la liste des moteurs disponibles."""
        return [engine.value for engine in self.engines.keys()]
    
    def get_primary_engine(self) -> Optional[str]:
        """Retourne le moteur principal."""
        return self.fallback_order[0].value if self.fallback_order else None
    
    def get_engine_info(self) -> Dict[str, Any]:
        """Retourne les informations sur les moteurs."""
        return {
            'available_engines': self.get_available_engines(),
            'primary_engine': self.get_primary_engine(),
            'fallback_order': [e.value for e in self.fallback_order],
            'total_engines': len(self.engines)
        }
