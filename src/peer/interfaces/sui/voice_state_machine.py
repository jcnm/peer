"""
Enhanced Voice Interface State Machine for Peer SUI.

This module implements an intelligent voice processing system with continuous listening,
smart silence detection, and proper state management.

√âtats de la machine:
- IDLE: En attente d'activation
- LISTENING: √âcoute active avec d√©tection de silence
- PROCESSING: Traitement STT et NLP
- INTENT_VALIDATION: Confirmation utilisateur
- AWAIT_RESPONSE: Attente de la r√©ponse du d√©mon
"""

import os
import time
import threading
import queue
import logging
import enum
from typing import Optional, List, Dict, Any, Callable
from dataclasses import dataclass, field
from collections import deque

import numpy as np

from peer.interfaces.sui.stt.audio_io import AudioCapture
from peer.interfaces.sui.stt.speech_recognizer import SpeechRecognizer
from peer.interfaces.sui.nlu.domain.nlp_engine import NLPEngine
from peer.interfaces.sui.tts.text_to_speech import TextToSpeech
from peer.interfaces.sui.domain.models import SpeechRecognitionResult, VoiceActivityMetrics


class VoiceInterfaceState(enum.Enum):
    """√âtats de la machine √† √©tats vocale."""
    IDLE = "idle"
    LISTENING = "listening"
    PROCESSING = "processing"
    INTENT_VALIDATION = "intent_validation"
    AWAIT_RESPONSE = "await_response"


@dataclass
class AudioBuffer:
    """Buffer audio avec m√©tadonn√©es."""
    data: bytes
    timestamp: float
    is_speech: bool = False
    energy_level: float = 0.0


@dataclass
class IntentContext:
    """Contexte d'une intention extraite."""
    text: str
    intent_type: str
    parameters: Dict[str, Any]
    confidence: float
    summary: str = ""


class VoiceStateMachine:
    """Machine √† √©tats pour le traitement vocal intelligent."""
    
    def __init__(self,
                 audio_capture: AudioCapture,
                 speech_recognizer: SpeechRecognizer,
                 nlp_engine: NLPEngine,
                 tts_engine: TextToSpeech,
                 peer_daemon=None):
        """
        Initialise la machine √† √©tats vocale.
        
        Args:
            audio_capture: Syst√®me de capture audio
            speech_recognizer: Moteur de reconnaissance vocale
            nlp_engine: Moteur de compr√©hension du langage naturel
            tts_engine: Moteur de synth√®se vocale
            peer_daemon: D√©mon Peer pour ex√©cution des commandes
        """
        self.logger = logging.getLogger("VoiceStateMachine")
        
        # Composants
        self.audio_capture = audio_capture
        self.speech_recognizer = speech_recognizer
        self.nlp_engine = nlp_engine
        self.tts_engine = tts_engine
        self.peer_daemon = peer_daemon
        
        # √âtat de la machine
        self.state = VoiceInterfaceState.IDLE
        self.is_running = False
        
        # Configuration des seuils de silence
        self.short_silence_ms = 600    # Court silence en ms
        self.long_silence_ms = 1200    # Long silence en ms
        self.max_audio_duration_s = 30  # Dur√©e max d'√©coute en secondes
        
        # Buffers audio
        self.audio_buffer: List[AudioBuffer] = []
        self.text_fragments: List[str] = []
        
        # Contexte actuel
        self.current_intent: Optional[IntentContext] = None
        self.intent_history: List[IntentContext] = []
        
        # Contr√¥leurs de silence
        self.silence_timer = 0.0
        self.last_speech_time = 0.0
        
        # Threads
        self.processing_thread: Optional[threading.Thread] = None
        self.listening_thread: Optional[threading.Thread] = None
        
        # Files d'attente
        self.command_queue = queue.Queue()
        self.global_command_queue = queue.Queue()
        
        # Commandes globales
        self.global_commands = ["stop", "arr√™te", "cancel", "annule", "wait", "attends", "resume", "reprends", "restart", "recommence"]
        
        # Handler de commandes (peut √™tre d√©fini apr√®s l'initialisation)
        self.command_handler: Optional[Callable] = None
        
        # Statistiques
        self.commands_processed = 0
        
        self.logger.info("üéõÔ∏è Machine √† √©tats vocale initialis√©e")
    
    @property
    def current_state(self) -> VoiceInterfaceState:
        """Retourne l'√©tat actuel de la machine."""
        return self.state
    
    def start(self):
        """D√©marre la machine √† √©tats vocale."""
        if self.is_running:
            self.logger.warning("‚ö†Ô∏è La machine √† √©tats est d√©j√† en cours d'ex√©cution")
            return
        
        self.is_running = True
        self.state = VoiceInterfaceState.IDLE
        
        # D√©marrer les threads
        self.listening_thread = threading.Thread(target=self._listening_loop, daemon=True)
        self.processing_thread = threading.Thread(target=self._processing_loop, daemon=True)
        
        self.listening_thread.start()
        self.processing_thread.start()
        
        self.logger.info("üéõÔ∏è Machine √† √©tats vocale d√©marr√©e")
        self.say("Interface vocale Peer pr√™te. Vous pouvez commencer √† parler.")
    
    def stop(self):
        """Arr√™te la machine √† √©tats vocale."""
        self.is_running = False
        self.state = VoiceInterfaceState.IDLE
        
        # Attendre l'arr√™t des threads
        if self.listening_thread and self.listening_thread.is_alive():
            self.listening_thread.join(timeout=2.0)
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=2.0)
        
        self.logger.info("üéõÔ∏è Machine √† √©tats vocale arr√™t√©e")
    
    def say(self, text: str, priority: int = 0):
        """Synth√®se vocale avec gestion des priorit√©s."""
        try:
            if self.tts_engine:
                self.logger.info(f"üîä TTS: {text}")
                result = self.tts_engine.synthesize(text)
                if not result.success:
                    self.logger.warning(f"‚ö†Ô∏è √âchec TTS: {result.error_message}")
            else:
                self.logger.warning("‚ö†Ô∏è Moteur TTS non disponible")
        except Exception as e:
            self.logger.error(f"‚ùå Erreur TTS: {e}")
    
    def _listening_loop(self):
        """Boucle d'√©coute continue."""
        self.logger.info("üéß Boucle d'√©coute d√©marr√©e")
        
        while self.is_running:
            try:
                # V√©rifier les commandes globales
                self._check_global_commands()
                
                # Machine √† √©tats
                if self.state == VoiceInterfaceState.IDLE:
                    self._handle_idle_state()
                elif self.state == VoiceInterfaceState.LISTENING:
                    self._handle_listening_state()
                elif self.state == VoiceInterfaceState.INTENT_VALIDATION:
                    self._handle_intent_validation_state()
                
                # Petite pause pour √©viter une surcharge CPU
                time.sleep(0.05)
                
            except Exception as e:
                self.logger.error(f"‚ùå Erreur dans la boucle d'√©coute: {e}")
                time.sleep(0.5)
        
        self.logger.info("üéß Boucle d'√©coute termin√©e")
    
    def _processing_loop(self):
        """Boucle de traitement des commandes."""
        self.logger.info("üß† Boucle de traitement d√©marr√©e")
        
        while self.is_running:
            try:
                # Traiter les commandes en attente
                try:
                    command_data = self.command_queue.get(timeout=1.0)
                    self._process_command(command_data)
                    self.command_queue.task_done()
                except queue.Empty:
                    continue
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erreur dans la boucle de traitement: {e}")
                time.sleep(0.5)
        
        self.logger.info("üß† Boucle de traitement termin√©e")
    
    def _handle_idle_state(self):
        """G√®re l'√©tat IDLE - d√©tection d'activation vocale."""
        if self.detect_hotword() or self.manual_trigger():
            self.state = VoiceInterfaceState.LISTENING
            self.start_microphone()
            self.logger.info("üé§ Transition vers LISTENING")
    
    def _handle_listening_state(self):
        """G√®re l'√©tat LISTENING - √©coute active avec d√©tection de silence."""
        current_time = time.time()
        
        # Capturer un chunk audio
        audio_chunk = self._record_audio_chunk()
        if not audio_chunk:
            return
        
        # Analyser le chunk
        audio_buffer = AudioBuffer(
            data=audio_chunk,
            timestamp=current_time,
            energy_level=self._calculate_energy(audio_chunk)
        )
        
        # D√©tecter l'activit√© vocale
        vad_result = self._detect_voice_activity(audio_chunk)
        audio_buffer.is_speech = vad_result.speech_detected
        
        self.audio_buffer.append(audio_buffer)
        
        if self.is_short_silence():
            # Court silence - traiter le chunk par STT
            self._send_to_stt(audio_chunk)
            self.silence_timer = 0
        elif self.is_long_silence():
            # Long silence - finaliser le traitement
            self._transition_to_processing()
        else:
            # Parole continue
            self.silence_timer += 0.05  # Correspond au sleep dans la boucle
            self.last_speech_time = current_time
        
        # V√©rifier la dur√©e maximale
        if len(self.audio_buffer) > 0:
            total_duration = current_time - self.audio_buffer[0].timestamp
            if total_duration > self.max_audio_duration_s:
                self.logger.info("‚è∞ Dur√©e maximale atteinte, traitement forc√©")
                self._transition_to_processing()
    
    def _handle_intent_validation_state(self):
        """G√®re l'√©tat INTENT_VALIDATION - confirmation utilisateur."""
        if not self.current_intent:
            self.state = VoiceInterfaceState.IDLE
            return
        
        # √âcouter la r√©ponse de confirmation
        audio_chunk = self._record_audio_chunk()
        if audio_chunk and self._detect_voice_activity(audio_chunk).speech_detected:
            confirmation_result = self._listen_for_confirmation_or_interrupt()
            
            if confirmation_result == "yes":
                self.stop_microphone()
                self.intent_history.append(self.current_intent)
                self._send_to_daemon(self.current_intent)
                self.state = VoiceInterfaceState.AWAIT_RESPONSE
            elif confirmation_result in ["no", "cancel"]:
                self.stop_microphone()
                self.say("D'accord, j'annule la demande.")
                self.state = VoiceInterfaceState.IDLE
                self.current_intent = None
            elif confirmation_result in self.global_commands:
                self._handle_global_command(confirmation_result)
                self.state = VoiceInterfaceState.IDLE
            else:
                self.stop_microphone()
                self.say("Je n'ai pas bien compris, peux-tu r√©p√©ter ?")
                self.state = VoiceInterfaceState.LISTENING
    
    def _transition_to_processing(self):
        """Transition vers l'√©tat PROCESSING."""
        self.stop_microphone()
        self.state = VoiceInterfaceState.PROCESSING
        
        # Mettre le traitement en queue
        processing_data = {
            'type': 'speech_processing',
            'audio_buffer': self.audio_buffer.copy(),
            'text_fragments': self.text_fragments.copy()
        }
        self.command_queue.put(processing_data)
        
        # R√©initialiser les buffers
        self.audio_buffer.clear()
        self.text_fragments.clear()
        self.silence_timer = 0
    
    def _process_command(self, command_data: Dict[str, Any]):
        """Traite une commande selon son type."""
        command_type = command_data.get('type')
        
        if command_type == 'speech_processing':
            self._process_speech_command(command_data)
        elif command_type == 'global_command':
            self._handle_global_command(command_data.get('command'))
        else:
            self.logger.warning(f"‚ö†Ô∏è Type de commande inconnu: {command_type}")
    
    def _process_speech_command(self, command_data: Dict[str, Any]):
        """Traite une commande vocale compl√®te."""
        try:
            self.say("Laisse-moi comprendre ce que tu veux dire‚Ä¶")
            
            # √âtape 1: Transcription STT
            text_fragments = command_data.get('text_fragments', [])
            full_text = self._concatenate_text_fragments(text_fragments)
            
            if not full_text.strip():
                self.say("D√©sol√©, je n'ai pas compris ce que tu as dit.")
                self.state = VoiceInterfaceState.IDLE
                return
            
            self.logger.info(f"üìù Texte complet: {full_text}")
            
            # √âtape 2: Analyse NLP
            nlp_output = self._run_nlp(full_text)
            if not nlp_output:
                self.say("D√©sol√©, je n'ai pas pu analyser ta demande.")
                self.state = VoiceInterfaceState.IDLE
                return
            
            # √âtape 3: Extraction d'intention NLU
            intent = self._run_nlu(nlp_output)
            if not intent:
                self.say("D√©sol√©, je n'ai pas compris ton intention.")
                self.state = VoiceInterfaceState.IDLE
                return
            
            self.current_intent = intent
            
            # √âtape 4: Confirmation utilisateur
            self.state = VoiceInterfaceState.INTENT_VALIDATION
            self.say(f"Tu veux faire ceci : {intent.summary}, c'est bien √ßa ?")
            self.start_microphone()
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors du traitement de la commande vocale: {e}")
            self.say("D√©sol√©, une erreur s'est produite lors du traitement.")
            self.state = VoiceInterfaceState.IDLE
    
    def _send_to_daemon(self, intent: IntentContext):
        """Envoie l'intention au d√©mon Peer avec feedback vocal am√©lior√©."""
        try:
            if not self.peer_daemon:
                self.say("Le service Peer n'est pas disponible. Je ne peux pas traiter votre demande.")
                self.state = VoiceInterfaceState.IDLE
                return
            
            # Announce what we're doing
            self.say(f"Je traite votre demande : {intent.summary}")
            
            # Utiliser le command_handler si disponible
            if self.command_handler:
                self.logger.info(f"üì§ Utilisation du command_handler: {intent.intent_type}")
                
                # Cr√©er un objet similaire √† celui attendu par le handler
                class MockIntentResult:
                    def __init__(self, intent_context):
                        self.command_type = intent_context.intent_type
                        self.parameters = intent_context.parameters
                        self.confidence = intent_context.confidence
                
                mock_intent = MockIntentResult(intent)
                
                # Announce the processing step
                self.say("Je transmets votre commande au syst√®me principal.")
                
                response_message = self.command_handler(mock_intent, intent.text)
                
                # Incr√©menter les statistiques
                self.commands_processed += 1
                
                if response_message:
                    # Provide detailed feedback about what was accomplished
                    completion_feedback = self._generate_completion_feedback(intent, response_message)
                    self.say(completion_feedback)
                else:
                    self.say("La commande a √©t√© trait√©e mais aucun r√©sultat sp√©cifique n'est disponible.")
                
                self.state = VoiceInterfaceState.IDLE
                return
            
            # Fallback vers la simulation si pas de handler
            self.logger.info(f"üì§ Envoi au d√©mon: {intent.intent_type}")
            self.say("Je transmets votre demande au syst√®me. Veuillez patienter un moment.")
            self.state = VoiceInterfaceState.AWAIT_RESPONSE
            threading.Timer(2.0, self._simulate_daemon_response).start()
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur lors de l'envoi au d√©mon: {e}")
            self.say(f"D√©sol√©, une erreur s'est produite lors du traitement de votre demande : {str(e)}")
            self.state = VoiceInterfaceState.IDLE
    
    def _generate_completion_feedback(self, intent: IntentContext, response_message: str) -> str:
        """Generate detailed feedback about what was accomplished."""
        intent_type = intent.intent_type.lower()
        
        # Create context-aware feedback based on the intent type
        feedback_templates = {
            "help": "J'ai r√©cup√©r√© les informations d'aide. Voici ce que j'ai trouv√© :",
            "status": "J'ai v√©rifi√© le statut du syst√®me. Voici les informations :",
            "time": "J'ai consult√© l'horloge syst√®me. Il est actuellement :",
            "date": "J'ai v√©rifi√© la date. Nous sommes le :",
            "version": "J'ai consult√© les informations de version. Voici les d√©tails :",
            "capabilities": "J'ai list√© mes capacit√©s. Voici ce que je peux faire :",
            "echo": "J'ai bien re√ßu votre message et je le r√©p√®te :",
            "quit": "J'ai initi√© la proc√©dure d'arr√™t. Le syst√®me va s'arr√™ter maintenant.",
            "analyze": "J'ai termin√© l'analyse. Voici les r√©sultats :",
            "analysis": "L'analyse est termin√©e. Voici ce que j'ai d√©couvert :",
        }
        
        prefix = feedback_templates.get(intent_type, "J'ai trait√© votre demande. Voici le r√©sultat :")
        
        # Combine the contextual prefix with the actual response
        if response_message and response_message.strip():
            return f"{prefix} {response_message}"
        else:
            return f"{prefix} La commande a √©t√© ex√©cut√©e avec succ√®s."
    
    def _simulate_daemon_response(self):
        """Simule une r√©ponse du d√©mon (√† remplacer par la vraie impl√©mentation)."""
        response = {
            'success': True,
            'message': 'Commande ex√©cut√©e avec succ√®s',
            'details': 'D√©tails de l\'ex√©cution...'
        }
        
        self.say(f"Voici le r√©sultat : {response['message']}")
        self.logger.info(f"üìã D√©tails: {response['details']}")
        self.state = VoiceInterfaceState.IDLE
    
    # M√©thodes utilitaires
    
    def detect_hotword(self) -> bool:
        """D√©tecte un mot d'activation."""
        # TODO: Impl√©menter la d√©tection de hotword
        return False
    
    def manual_trigger(self) -> bool:
        """D√©clenchement manuel (toujours actif pour l'instant)."""
        return True
    
    def start_microphone(self):
        """Active le microphone."""
        if self.audio_capture:
            try:
                self.audio_capture.start_recording()
                self.logger.debug("üé§ Microphone activ√©")
            except Exception as e:
                self.logger.error(f"‚ùå Erreur activation microphone: {e}")
    
    def stop_microphone(self):
        """D√©sactive le microphone."""
        if self.audio_capture:
            try:
                self.audio_capture.stop_recording()
                self.logger.debug("üé§ Microphone d√©sactiv√©")
            except Exception as e:
                self.logger.error(f"‚ùå Erreur d√©sactivation microphone: {e}")
    
    def _record_audio_chunk(self) -> Optional[bytes]:
        """Enregistre un chunk audio."""
        try:
            if self.audio_capture and self.audio_capture.is_recording:
                return self.audio_capture.get_audio_chunk()
        except Exception as e:
            self.logger.error(f"‚ùå Erreur enregistrement chunk: {e}")
        return None
    
    def _calculate_energy(self, audio_data: bytes) -> float:
        """Calcule l'√©nergie d'un chunk audio."""
        try:
            if not audio_data:
                return 0.0
            audio_np = np.frombuffer(audio_data, dtype=np.int16)
            return float(np.sqrt(np.mean(audio_np.astype(np.float64) ** 2)))
        except Exception:
            return 0.0
    
    def _detect_voice_activity(self, audio_data: bytes) -> VoiceActivityMetrics:
        """D√©tecte l'activit√© vocale dans un chunk."""
        try:
            if self.audio_capture:
                # Utiliser la m√©thode VAD existante
                return self.audio_capture._detect_voice_activity(audio_data)
        except Exception as e:
            self.logger.error(f"‚ùå Erreur VAD: {e}")
        
        # Fallback simple bas√© sur l'√©nergie
        energy = self._calculate_energy(audio_data)
        return VoiceActivityMetrics(
            speech_detected=energy > 300,  # Seuil simple
            energy_level=energy,
            speech_probability=min(1.0, energy / 1000.0)
        )
    
    def is_short_silence(self) -> bool:
        """V√©rifie si on a un court silence."""
        return self.silence_timer > (self.short_silence_ms / 1000.0)
    
    def is_long_silence(self) -> bool:
        """V√©rifie si on a un long silence."""
        return self.silence_timer > (self.long_silence_ms / 1000.0)
    
    def _send_to_stt(self, audio_chunk: bytes):
        """Envoie un chunk audio au STT."""
        try:
            if self.speech_recognizer:
                # Conversion des bytes en numpy array
                audio_np = np.frombuffer(audio_chunk, dtype=np.int16).astype(np.float32) / 32768.0
                result = self.speech_recognizer.transcribe(audio_np)
                if result and result.text.strip():
                    self.text_fragments.append(result.text.strip())
                    self.logger.debug(f"üìù Fragment STT: {result.text}")
        except Exception as e:
            self.logger.error(f"‚ùå Erreur STT: {e}")
    
    def _concatenate_text_fragments(self, fragments: List[str]) -> str:
        """Concat√®ne les fragments de texte."""
        return " ".join(fragment.strip() for fragment in fragments if fragment.strip())
    
    def _run_nlp(self, text: str) -> Optional[Dict[str, Any]]:
        """Ex√©cute l'analyse NLP."""
        try:
            if self.nlp_engine:
                # TODO: Adapter selon l'interface NLP r√©elle
                return {"processed_text": text, "entities": [], "sentiment": "neutral"}
        except Exception as e:
            self.logger.error(f"‚ùå Erreur NLP: {e}")
        return None
    
    def _run_nlu(self, nlp_output: Dict[str, Any]) -> Optional[IntentContext]:
        """Ex√©cute l'extraction d'intention."""
        try:
            if self.nlp_engine:
                # TODO: Utiliser la vraie m√©thode d'extraction d'intention
                text = nlp_output.get("processed_text", "")
                intent_result = self.nlp_engine.extract_intent(text)
                
                if intent_result:
                    return IntentContext(
                        text=text,
                        intent_type=intent_result.command_type,
                        parameters=intent_result.parameters,
                        confidence=intent_result.confidence,
                        summary=f"{intent_result.command_type} ({', '.join(str(v) for v in intent_result.parameters.values())})"
                    )
        except Exception as e:
            self.logger.error(f"‚ùå Erreur NLU: {e}")
        return None
    
    def _listen_for_confirmation_or_interrupt(self) -> str:
        """√âcoute une r√©ponse de confirmation ou une commande globale."""
        try:
            # TODO: Impl√©menter l'√©coute de confirmation
            # Pour l'instant, retourner une r√©ponse simul√©e
            return "yes"
        except Exception as e:
            self.logger.error(f"‚ùå Erreur √©coute confirmation: {e}")
            return "error"
    
    def _check_global_commands(self):
        """V√©rifie les commandes globales."""
        try:
            # TODO: Impl√©menter la d√©tection de commandes globales
            pass
        except Exception as e:
            self.logger.error(f"‚ùå Erreur v√©rification commandes globales: {e}")
    
    def _handle_global_command(self, command: str):
        """Traite une commande globale."""
        command = command.lower().strip()
        
        if command in ["stop", "arr√™te"]:
            self.say("D'accord, j'arr√™te.")
            self.stop()
        elif command in ["cancel", "annule"]:
            self.say("Commande annul√©e.")
            self._cancel_last_intent()
            self.state = VoiceInterfaceState.IDLE
        elif command in ["wait", "attends"]:
            self._pause_processing()
            self.say("En pause, dis 'reprends' pour continuer.")
        elif command in ["resume", "reprends"]:
            self._resume_processing()
            self.say("Je reprends.")
        elif command in ["restart", "recommence"]:
            self.state = VoiceInterfaceState.IDLE
            self.say("Red√©marrage de l'interface vocale.")
    
    def _cancel_last_intent(self):
        """Annule la derni√®re intention."""
        if self.current_intent:
            self.logger.info(f"üö´ Intention annul√©e: {self.current_intent.summary}")
            self.current_intent = None
    
    def _pause_processing(self):
        """Met en pause le traitement."""
        # TODO: Impl√©menter la pause
        pass
    
    def _resume_processing(self):
        """Reprend le traitement."""
        # TODO: Impl√©menter la reprise
        pass
```
</copilot-edited-file>
